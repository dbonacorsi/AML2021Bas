{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"},"colab":{"name":"AML_8_Modelling_CompareModels.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"7An3uCq3BbQF"},"source":["# Compare ML Algorithms"]},{"cell_type":"markdown","metadata":{"id":"RMT63yygBbQG"},"source":["It is important to compare the respective performance of multiple different ML algorithms consistently. \n","\n","We will discover how you can create a test harness to compare multiple different ML algorithms in Python with sklearn. You can use this test harness as a template on your own ML problems and add more and different algorithms to compare. \n","\n","So, the goal is to learn:\n","1. How to formulate an experiment to directly compare ML algorithms\n","2. How to build a reusable template for evaluating the performance of multiple algorithms on one dataset\n","3. How to report and visualize the results when comparing algorithm performance."]},{"cell_type":"markdown","metadata":{"id":"LbZQ4AZxBbQH"},"source":["## Choose \"the best\" ML algorithm"]},{"cell_type":"markdown","metadata":{"id":"PvIHI_W7Q1hA"},"source":["You should use a number of different ways of looking at the estimated accuracy of your ML algorithms in order to choose the one or two algorithm to finalize. A way to do this is to use visualization methods to show the average accuracy, variance and other properties of the distribution of model accuracies. \n","\n","We will discover how you can do that in Python with scikit-learn."]},{"cell_type":"markdown","metadata":{"id":"V9uyvtKcBbQI"},"source":["## Consistent comparison of ML algos"]},{"cell_type":"markdown","metadata":{"id":"JM58JfmaRD-y"},"source":["In the example below 6 different classification algorithms are compared on a single dataset:\n","\n","* Logistic Regression\n","* Linear Discriminant Analysis\n","* k-Nearest Neighbors\n","* Classification and Regression Trees\n","* Naive Bayes\n","* Support Vector Machines\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O0yWhosvRjwN"},"source":["The dataset is the diabetes one. The problem has 2 classes and 8 numeric input variables of varying scales. The 10-fold cross-validation procedure is used to evaluate each algorithm, importantly configured with the same random seed to ensure that the same splits to the training data are performed and that each algorithm is evaluated in precisely the same way. Each algorithm is given a short name, useful for summarizing results afterward."]},{"cell_type":"markdown","metadata":{"id":"73BUWzHZRcPh"},"source":["## 0. Import the data"]},{"cell_type":"code","metadata":{"id":"VOTtvlZKReno","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1617857404806,"user_tz":-120,"elapsed":1693,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}},"outputId":"8b1a89da-d8a7-46e5-db83-97ae3ee5736a"},"source":["import pandas as pd\n","\n","url = 'https://raw.githubusercontent.com/dbonacorsi/AML2021Bas/main/datasets/pima-indians-diabetes.data.csv'\n","\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","data = pd.read_csv(url, names=names)\n","data"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     preg  plas  pres  skin  test  mass   pedi  age  class\n","0       6   148    72    35     0  33.6  0.627   50      1\n","1       1    85    66    29     0  26.6  0.351   31      0\n","2       8   183    64     0     0  23.3  0.672   32      1\n","3       1    89    66    23    94  28.1  0.167   21      0\n","4       0   137    40    35   168  43.1  2.288   33      1\n","5       5   116    74     0     0  25.6  0.201   30      0\n","6       3    78    50    32    88  31.0  0.248   26      1\n","7      10   115     0     0     0  35.3  0.134   29      0\n","8       2   197    70    45   543  30.5  0.158   53      1\n","9       8   125    96     0     0   0.0  0.232   54      1\n","10      4   110    92     0     0  37.6  0.191   30      0\n","11     10   168    74     0     0  38.0  0.537   34      1\n","12     10   139    80     0     0  27.1  1.441   57      0\n","13      1   189    60    23   846  30.1  0.398   59      1\n","14      5   166    72    19   175  25.8  0.587   51      1\n","15      7   100     0     0     0  30.0  0.484   32      1\n","16      0   118    84    47   230  45.8  0.551   31      1\n","17      7   107    74     0     0  29.6  0.254   31      1\n","18      1   103    30    38    83  43.3  0.183   33      0\n","19      1   115    70    30    96  34.6  0.529   32      1\n","20      3   126    88    41   235  39.3  0.704   27      0\n","21      8    99    84     0     0  35.4  0.388   50      0\n","22      7   196    90     0     0  39.8  0.451   41      1\n","23      9   119    80    35     0  29.0  0.263   29      1\n","24     11   143    94    33   146  36.6  0.254   51      1\n","25     10   125    70    26   115  31.1  0.205   41      1\n","26      7   147    76     0     0  39.4  0.257   43      1\n","27      1    97    66    15   140  23.2  0.487   22      0\n","28     13   145    82    19   110  22.2  0.245   57      0\n","29      5   117    92     0     0  34.1  0.337   38      0\n","..    ...   ...   ...   ...   ...   ...    ...  ...    ...\n","738     2    99    60    17   160  36.6  0.453   21      0\n","739     1   102    74     0     0  39.5  0.293   42      1\n","740    11   120    80    37   150  42.3  0.785   48      1\n","741     3   102    44    20    94  30.8  0.400   26      0\n","742     1   109    58    18   116  28.5  0.219   22      0\n","743     9   140    94     0     0  32.7  0.734   45      1\n","744    13   153    88    37   140  40.6  1.174   39      0\n","745    12   100    84    33   105  30.0  0.488   46      0\n","746     1   147    94    41     0  49.3  0.358   27      1\n","747     1    81    74    41    57  46.3  1.096   32      0\n","748     3   187    70    22   200  36.4  0.408   36      1\n","749     6   162    62     0     0  24.3  0.178   50      1\n","750     4   136    70     0     0  31.2  1.182   22      1\n","751     1   121    78    39    74  39.0  0.261   28      0\n","752     3   108    62    24     0  26.0  0.223   25      0\n","753     0   181    88    44   510  43.3  0.222   26      1\n","754     8   154    78    32     0  32.4  0.443   45      1\n","755     1   128    88    39   110  36.5  1.057   37      1\n","756     7   137    90    41     0  32.0  0.391   39      0\n","757     0   123    72     0     0  36.3  0.258   52      1\n","758     1   106    76     0     0  37.5  0.197   26      0\n","759     6   190    92     0     0  35.5  0.278   66      1\n","760     2    88    58    26    16  28.4  0.766   22      0\n","761     9   170    74    31     0  44.0  0.403   43      1\n","762     9    89    62     0     0  22.5  0.142   33      0\n","763    10   101    76    48   180  32.9  0.171   63      0\n","764     2   122    70    27     0  36.8  0.340   27      0\n","765     5   121    72    23   112  26.2  0.245   30      0\n","766     1   126    60     0     0  30.1  0.349   47      1\n","767     1    93    70    31     0  30.4  0.315   23      0\n","\n","[768 rows x 9 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preg</th>\n","      <th>plas</th>\n","      <th>pres</th>\n","      <th>skin</th>\n","      <th>test</th>\n","      <th>mass</th>\n","      <th>pedi</th>\n","      <th>age</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>116</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>25.6</td>\n","      <td>0.201</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3</td>\n","      <td>78</td>\n","      <td>50</td>\n","      <td>32</td>\n","      <td>88</td>\n","      <td>31.0</td>\n","      <td>0.248</td>\n","      <td>26</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10</td>\n","      <td>115</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.3</td>\n","      <td>0.134</td>\n","      <td>29</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>197</td>\n","      <td>70</td>\n","      <td>45</td>\n","      <td>543</td>\n","      <td>30.5</td>\n","      <td>0.158</td>\n","      <td>53</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>8</td>\n","      <td>125</td>\n","      <td>96</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.232</td>\n","      <td>54</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>4</td>\n","      <td>110</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>37.6</td>\n","      <td>0.191</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>10</td>\n","      <td>168</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>0.537</td>\n","      <td>34</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>10</td>\n","      <td>139</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>27.1</td>\n","      <td>1.441</td>\n","      <td>57</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>189</td>\n","      <td>60</td>\n","      <td>23</td>\n","      <td>846</td>\n","      <td>30.1</td>\n","      <td>0.398</td>\n","      <td>59</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>5</td>\n","      <td>166</td>\n","      <td>72</td>\n","      <td>19</td>\n","      <td>175</td>\n","      <td>25.8</td>\n","      <td>0.587</td>\n","      <td>51</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>7</td>\n","      <td>100</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30.0</td>\n","      <td>0.484</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0</td>\n","      <td>118</td>\n","      <td>84</td>\n","      <td>47</td>\n","      <td>230</td>\n","      <td>45.8</td>\n","      <td>0.551</td>\n","      <td>31</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>7</td>\n","      <td>107</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>29.6</td>\n","      <td>0.254</td>\n","      <td>31</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1</td>\n","      <td>103</td>\n","      <td>30</td>\n","      <td>38</td>\n","      <td>83</td>\n","      <td>43.3</td>\n","      <td>0.183</td>\n","      <td>33</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1</td>\n","      <td>115</td>\n","      <td>70</td>\n","      <td>30</td>\n","      <td>96</td>\n","      <td>34.6</td>\n","      <td>0.529</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>3</td>\n","      <td>126</td>\n","      <td>88</td>\n","      <td>41</td>\n","      <td>235</td>\n","      <td>39.3</td>\n","      <td>0.704</td>\n","      <td>27</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>8</td>\n","      <td>99</td>\n","      <td>84</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.4</td>\n","      <td>0.388</td>\n","      <td>50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>7</td>\n","      <td>196</td>\n","      <td>90</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>39.8</td>\n","      <td>0.451</td>\n","      <td>41</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>9</td>\n","      <td>119</td>\n","      <td>80</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>29.0</td>\n","      <td>0.263</td>\n","      <td>29</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>11</td>\n","      <td>143</td>\n","      <td>94</td>\n","      <td>33</td>\n","      <td>146</td>\n","      <td>36.6</td>\n","      <td>0.254</td>\n","      <td>51</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>10</td>\n","      <td>125</td>\n","      <td>70</td>\n","      <td>26</td>\n","      <td>115</td>\n","      <td>31.1</td>\n","      <td>0.205</td>\n","      <td>41</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>7</td>\n","      <td>147</td>\n","      <td>76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>39.4</td>\n","      <td>0.257</td>\n","      <td>43</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>1</td>\n","      <td>97</td>\n","      <td>66</td>\n","      <td>15</td>\n","      <td>140</td>\n","      <td>23.2</td>\n","      <td>0.487</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>13</td>\n","      <td>145</td>\n","      <td>82</td>\n","      <td>19</td>\n","      <td>110</td>\n","      <td>22.2</td>\n","      <td>0.245</td>\n","      <td>57</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>5</td>\n","      <td>117</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>34.1</td>\n","      <td>0.337</td>\n","      <td>38</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>738</th>\n","      <td>2</td>\n","      <td>99</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>160</td>\n","      <td>36.6</td>\n","      <td>0.453</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>739</th>\n","      <td>1</td>\n","      <td>102</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>39.5</td>\n","      <td>0.293</td>\n","      <td>42</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>740</th>\n","      <td>11</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>37</td>\n","      <td>150</td>\n","      <td>42.3</td>\n","      <td>0.785</td>\n","      <td>48</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>741</th>\n","      <td>3</td>\n","      <td>102</td>\n","      <td>44</td>\n","      <td>20</td>\n","      <td>94</td>\n","      <td>30.8</td>\n","      <td>0.400</td>\n","      <td>26</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>742</th>\n","      <td>1</td>\n","      <td>109</td>\n","      <td>58</td>\n","      <td>18</td>\n","      <td>116</td>\n","      <td>28.5</td>\n","      <td>0.219</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>743</th>\n","      <td>9</td>\n","      <td>140</td>\n","      <td>94</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32.7</td>\n","      <td>0.734</td>\n","      <td>45</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>744</th>\n","      <td>13</td>\n","      <td>153</td>\n","      <td>88</td>\n","      <td>37</td>\n","      <td>140</td>\n","      <td>40.6</td>\n","      <td>1.174</td>\n","      <td>39</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>745</th>\n","      <td>12</td>\n","      <td>100</td>\n","      <td>84</td>\n","      <td>33</td>\n","      <td>105</td>\n","      <td>30.0</td>\n","      <td>0.488</td>\n","      <td>46</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>746</th>\n","      <td>1</td>\n","      <td>147</td>\n","      <td>94</td>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>49.3</td>\n","      <td>0.358</td>\n","      <td>27</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>747</th>\n","      <td>1</td>\n","      <td>81</td>\n","      <td>74</td>\n","      <td>41</td>\n","      <td>57</td>\n","      <td>46.3</td>\n","      <td>1.096</td>\n","      <td>32</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>748</th>\n","      <td>3</td>\n","      <td>187</td>\n","      <td>70</td>\n","      <td>22</td>\n","      <td>200</td>\n","      <td>36.4</td>\n","      <td>0.408</td>\n","      <td>36</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>749</th>\n","      <td>6</td>\n","      <td>162</td>\n","      <td>62</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24.3</td>\n","      <td>0.178</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>750</th>\n","      <td>4</td>\n","      <td>136</td>\n","      <td>70</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>31.2</td>\n","      <td>1.182</td>\n","      <td>22</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>751</th>\n","      <td>1</td>\n","      <td>121</td>\n","      <td>78</td>\n","      <td>39</td>\n","      <td>74</td>\n","      <td>39.0</td>\n","      <td>0.261</td>\n","      <td>28</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>752</th>\n","      <td>3</td>\n","      <td>108</td>\n","      <td>62</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0.223</td>\n","      <td>25</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>753</th>\n","      <td>0</td>\n","      <td>181</td>\n","      <td>88</td>\n","      <td>44</td>\n","      <td>510</td>\n","      <td>43.3</td>\n","      <td>0.222</td>\n","      <td>26</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>754</th>\n","      <td>8</td>\n","      <td>154</td>\n","      <td>78</td>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>32.4</td>\n","      <td>0.443</td>\n","      <td>45</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>755</th>\n","      <td>1</td>\n","      <td>128</td>\n","      <td>88</td>\n","      <td>39</td>\n","      <td>110</td>\n","      <td>36.5</td>\n","      <td>1.057</td>\n","      <td>37</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>756</th>\n","      <td>7</td>\n","      <td>137</td>\n","      <td>90</td>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>32.0</td>\n","      <td>0.391</td>\n","      <td>39</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>757</th>\n","      <td>0</td>\n","      <td>123</td>\n","      <td>72</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>36.3</td>\n","      <td>0.258</td>\n","      <td>52</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>758</th>\n","      <td>1</td>\n","      <td>106</td>\n","      <td>76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>37.5</td>\n","      <td>0.197</td>\n","      <td>26</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>759</th>\n","      <td>6</td>\n","      <td>190</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.5</td>\n","      <td>0.278</td>\n","      <td>66</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>760</th>\n","      <td>2</td>\n","      <td>88</td>\n","      <td>58</td>\n","      <td>26</td>\n","      <td>16</td>\n","      <td>28.4</td>\n","      <td>0.766</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>761</th>\n","      <td>9</td>\n","      <td>170</td>\n","      <td>74</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>44.0</td>\n","      <td>0.403</td>\n","      <td>43</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>762</th>\n","      <td>9</td>\n","      <td>89</td>\n","      <td>62</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>22.5</td>\n","      <td>0.142</td>\n","      <td>33</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>763</th>\n","      <td>10</td>\n","      <td>101</td>\n","      <td>76</td>\n","      <td>48</td>\n","      <td>180</td>\n","      <td>32.9</td>\n","      <td>0.171</td>\n","      <td>63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>2</td>\n","      <td>122</td>\n","      <td>70</td>\n","      <td>27</td>\n","      <td>0</td>\n","      <td>36.8</td>\n","      <td>0.340</td>\n","      <td>27</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>765</th>\n","      <td>5</td>\n","      <td>121</td>\n","      <td>72</td>\n","      <td>23</td>\n","      <td>112</td>\n","      <td>26.2</td>\n","      <td>0.245</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>766</th>\n","      <td>1</td>\n","      <td>126</td>\n","      <td>60</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30.1</td>\n","      <td>0.349</td>\n","      <td>47</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>767</th>\n","      <td>1</td>\n","      <td>93</td>\n","      <td>70</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>30.4</td>\n","      <td>0.315</td>\n","      <td>23</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>768 rows × 9 columns</p>\n","</div>"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"RhQZaywWR0hw","executionInfo":{"status":"ok","timestamp":1617857404809,"user_tz":-120,"elapsed":1647,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["array = data.values\n","X = array[:,0:8]\n","Y = array[:,8]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y4aVDUBrBbQJ","executionInfo":{"status":"ok","timestamp":1617857405812,"user_tz":-120,"elapsed":2645,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["from matplotlib import pyplot\n","#\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","#\n","from sklearn.linear_model import LogisticRegression                         # <---\n","#\n","from sklearn.tree import DecisionTreeClassifier                             # <---\n","#\n","from sklearn.neighbors import KNeighborsClassifier                          # <---\n","#\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis        # <---\n","#\n","from sklearn.naive_bayes import GaussianNB                                  # <---\n","#\n","from sklearn.svm import SVC                                                 # <---"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzX0x44jTArw"},"source":["Everything meaningful is in this cell:"]},{"cell_type":"code","metadata":{"id":"Na-zQ2SxBbQN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617857406287,"user_tz":-120,"elapsed":3101,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}},"outputId":"0c467687-84ae-4ded-ef05-291b629eebf6"},"source":["# Compare Algorithms\n","\n","# prepare models\n","models = []\n","models.append(( 'LR'   , LogisticRegression()))                                # avoid warnings with (solver='lbfgs', max_iter=500)\n","models.append(( 'LDA'  , LinearDiscriminantAnalysis()))\n","models.append(( 'KNN'  , KNeighborsClassifier()))\n","models.append(( 'CART' , DecisionTreeClassifier()))\n","models.append(( 'NB'   , GaussianNB()))\n","models.append(( 'SVM' , SVC()))                                                # avoid warnings with (gamma='scale')\n","\n","# evaluate each model in turn\n","results = []\n","names = []\n","scoring = 'accuracy'\n","for name, model in models:\n","  kfold = KFold(n_splits=10, random_state=7)\n","  cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n","  results.append(cv_results)\n","  names.append(name)\n","  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n","  print(msg)\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["LR: 0.769515 (0.048411)\n","LDA: 0.773462 (0.051592)\n","KNN: 0.726555 (0.061821)\n","CART: 0.692618 (0.072294)\n","NB: 0.755178 (0.042766)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n","  \"avoid this warning.\", FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["SVM: 0.651025 (0.072141)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hbS1-c1gBbQR"},"source":["Running the example provides a list of each algorithm short name, the mean accuracy and the standard deviation accuracy. "]},{"cell_type":"code","metadata":{"id":"rKWO99ltTWF4","colab":{"base_uri":"https://localhost:8080/","height":294},"executionInfo":{"status":"ok","timestamp":1617857406530,"user_tz":-120,"elapsed":3324,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}},"outputId":"24600921-3783-4971-f297-0d5254c3b743"},"source":["# boxplot algorithm comparison\n","fig = pyplot.figure()\n","fig.suptitle('Algorithms comparison')\n","ax = fig.add_subplot(111)\n","pyplot.boxplot(results)\n","ax.set_xticklabels(names)\n","pyplot.show()"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"s39Uzuu4Td7q"},"source":["The example also provides a box and whisker plot showing the spread of the accuracy scores across each cross-validation fold for each algorithm. From these results, a suggestion could easily arise: **which models are worthy of further study on this problem?**"]},{"cell_type":"markdown","metadata":{"id":"PmZWKQBaBbQR"},"source":["## Summary"]},{"cell_type":"markdown","metadata":{"id":"idyMH0jfBbQS"},"source":["What we did:\n","\n","* we discovered how to evaluate multiple different ML algorithms on a dataset in Python with scikit-learn. You learned how to both use the same test harness to evaluate the algorithms and how to summarize the results both numerically and using a box and whisker plot. You can use this recipe as a template for evaluating multiple algorithms on your own problems."]}]}